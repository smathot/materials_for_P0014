Here we report two experiments in which we tested the hypothesis that there is a sustained bias of visual attention toward stimuli that match the contents of visual working memory (memory-match stimuli). We found that the eyes were briefly captured by memory-match stimuli (%FigGazeDev and %FigGazeTrace), consistent with previous studies [@Olivers2006;@Hollingworth2008]. However, this initial bias did not result in a sustained shift of attention as measured through pupillometry (%FigPupilTrace and %FigIndividual); rather, later in time, attention appeared to be biased away from memory-match stimuli.

Our results speak against single-state models according to which visual-working memory is a uniform attentional template: These models would predict a sustained attention bias toward memory-match stimuli. Rather, our results are consistent with recent models according to which working-memory items can be in different states [@Olivers2011;@Zokaei2014Flex]: prioritized or accessory. An item is *prioritized* when it is behaviorally relevant; there can only a single prioritized item at a time. An item is *accessory* when it is not directly relevant, yet relevant enough to be remembered; there can be several accessory items at a time.

The difference between prioritized and accessory working-memory states was demonstrated in a compelling study by Zokaei, Manohar, Husain, and Feredoes [-@Zokaei2014Causal, Exp. 1]. In their experiment, participants remembered the motion direction of two moving stimuli, one red and one green. Next, a red or green cue was shown, and participants indicated the location of the corresponding memorized stimulus; presumably, this caused the cued item to become prioritized (because it was immediately relevant), and the uncued item to become accessory. Next, transcranial magnetic stimulation (TMS; either high or low intensity) was applied over brain area MT+, thus disrupting brain activity in the region that encodes motion direction. Finally, participants saw a red or green moving test stimulus, and matched the motion direction of the test stimulus to the corresponding memorized stimulus. Zokaei and colleagues [-@Zokaei2014Causal] found that high-intensity TMS reduced working-memory precision, but--crucially--only for the prioritized (cued) item. This suggests that prioritized working-memory items are represented in visual cortices (area MT+ in this case), while accessory items are not.

Following the idea that working memory guides attention by modulating baseline activity in visual cortices [e.g., @Chelazzi1993], the results of Zokaei and colleagues [-@Zokaei2014Causal] suggest that only prioritized items should guide attention. This was confirmed by Van Moorselaar, Theeuwes, and Olivers [-@Van+moorselaar2014Comp, Exp. 4], who used a design similar to that used by Olivers and colleagues [-@Olivers2006, see Introduction] with the important difference that participants kept two colors in memory, rather than one. Both colors were tested on every trial, but an arrow cue indicated which color was tested first; the cued item thus became prioritized (what comes first is most important), and the uncued item became accessory. Next, participants performed a visual-search task. Response times on the visual-search task increased when there was a memory-match distractor, suggesting that memory-match distractors captured attention [replicating @Olivers2006]. But, crucially, this only happened for distractors that matched the prioritized (cued) item; distractors that matched the accessory item did not attract attention more than did neutral distractors. This suggests that prioritized items guide attention, while accessory items do not.

The results of the present study could be explained as follows in a multi-state model of working memory. Only one color needed to be remembered on each trial. Therefore, this color was initially prioritized, and captured attention; this explains why the memory-match probe captured the eyes at the start of the retention interval (%FigGazeTrace). However, the color of the memory-match probe was easily confused with the to-be-remembered color, because both were different shades of the same color category. To minimize confusion, participants may have put the to-be-rembered color in an accessory state, and strategically avoided attending toward the memory-match probe; this could explain the attention bias away from the memory-match probe that emerged later in the retention interval, as measured through pupillometry (%FigPupilTrace).

This interpretation is reminiscent of a study by Sawaki and Luck [-@SawakiLuck2011], who measured event-related potentials (ERP) in a design similar to ours. In their experiment, participants remembered the orientation of a colored rectangle. In the retention interval, two task-irrelevant probes were presented, one of which matched the color of the memorized rectangle. Crucially, the memory-match probe evoked a distractor positivity, an ERP component that is believed to index suppression of attention [@Hickey2009JCogNeurosci]. Together, our results and those of Sawaki and Luck [-@SawakiLuck2011] suggest that whether attention is biased toward or away from memory-match stimuli depends very much on the task.

We have used a new pupillometric technique, which is based on the assumption that the pupil is larger when you attend to dark, compared to bright, stimuli. But is this logic valid? And is this technique sufficiently reliable? With respect to validity, we and others have systematically found that the pupillary light response, when combined with a bright/ dark manipulation, measures various forms of visual attention [reviewed in @Mathôt2015CurrDir]: voluntary [@Mathôt2013Plos;@Binda2013JNeuro;@Naber2013Osc;@Binda2015Increases], involuntary [@Mathôt2014Exo], presaccadic [@MathôtLinden2015Eye]+[; see also @Ebitz2014], and feature-based attention [@Binda2014Feature]. With respect to reliability, we have previously shown that manual responses and the pupillary light response are about equally sensitive measures of attention [@Mathôt2013Plos]. This high sensitivity is corroborated by our ongoing work on a pupillometric method to decode the focus of attention, which reaches over 90% accuracy on single trials [@Mathôt2015Interface]. Taken together, the pupillary light response seems to be a valid and reliable measure of visual attention.

In summary, we have used pupillometry and eye movements to test whether and when attention is biased toward stimuli that match the contents of visual working memory (memory-match stimuli). We found that the eyes were briefly drawn toward memory-match stimuli, but that there was no sustained attentional bias toward memory-match stimuli; if anything, attention was biased away from them [cf. @SawakiLuck2011]. In line with multi-state models of working memory [@Olivers2011;@Zokaei2014Flex], we have suggested that you can avoid attention from being captured by memory-match stimuli by putting them in an accessory working-memory state. Finally, we suggest that pupillometry, especially when used with a bright/ dark manipulation, is a promising way to unobtrusively track attention over time.
